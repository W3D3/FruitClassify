{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11c05a044f27e0cfd9d38927523d86f9fcd1ef02"
   },
   "source": [
    "In this kernel, I will try building a CNN from scratch for multi-class classification for the fruits dataset. In this dataset, we have a total of 55244 images which are divided into two folders - training set of 41322 images and testing set of 13877 images. The size of the given images is 100 * 100. We have 81 classes of fruits.\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "8ae6b0f622f3371e629d3bc916d881b11b7a5bf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete!\n",
      "Training set size :  48906\n",
      "Testing set size :  16422\n",
      "['../input/Training/Plum 2/1_100.jpg'\n",
      " '../input/Training/Lemon Meyer/1_100.jpg'\n",
      " '../input/Training/Nectarine/r_204_100.jpg' ...\n",
      " '../input/Training/Strawberry/224_100.jpg'\n",
      " '../input/Training/Strawberry Wedge/r_226_100.jpg'\n",
      " '../input/Training/Apple Red 1/r_132_100.jpg']\n"
     ]
    }
   ],
   "source": [
    "# First, we are going to load the file names and their respective target labels into numpy array! \n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "\n",
    "train_dir = '../input/Training'\n",
    "test_dir = '../input/Test'\n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np.array(data['target'])\n",
    "    target_labels = np.array(data['target_names'])\n",
    "    return files,targets,target_labels\n",
    "    \n",
    "x_train, y_train,target_labels = load_dataset(train_dir)\n",
    "x_test, y_test,_ = load_dataset(test_dir)\n",
    "print('Loading complete!')\n",
    "\n",
    "print('Training set size : ' , x_train.shape[0])\n",
    "print('Testing set size : ', x_test.shape[0])\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "f09063e1d62bcf1fe28eb840ee93fd95fcfdb6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]\n"
     ]
    }
   ],
   "source": [
    "# Let's confirm the number of classes :p\n",
    "no_of_classes = len(np.unique(y_train))\n",
    "print(no_of_classes)\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "27cf6d93da0e851e97f341be0dd7060eba55ce0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75 47 56 58  6 76 68 41 88 18]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:10])\n",
    "# target labels are numbers corresponding to class label. We need to change them to a vector of 81 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "299c14e9e0a8fc0e5fde71bf144a012dee02160b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train,no_of_classes)\n",
    "y_test = np_utils.to_categorical(y_test,no_of_classes)\n",
    "y_train[0] # Note that only one element has value 1(corresponding to its label) and others are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "726a160122475e7d47e0c00bf617b7a5c0838ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vaildation X :  (7000,)\n",
      "Vaildation y : (7000, 95)\n",
      "Test X :  (2422,)\n",
      "Test y :  (2422, 95)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Now, we have to divide the validation set into test and validation set\n",
    "x_test,x_valid = x_test[7000:],x_test[:7000]\n",
    "y_test,y_vaild = y_test[7000:],y_test[:7000]\n",
    "print('Vaildation X : ',x_valid.shape)\n",
    "print('Vaildation y :',y_vaild.shape)\n",
    "print('Test X : ',x_test.shape)\n",
    "print('Test y : ',y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "aa2cbb8c65386cef369abc49c7a4c1da3957d08e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input/Training/Plum 2/1_100.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]\n",
    "# training data is just file names of images. We need to convert them into pixel matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "1b3ab256679300f07d026017477092ebc5c71594",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file '../input/Training/Apple Red 1/.DS_Store'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-943ea1b0f2ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages_as_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_image_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training set shape : '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-943ea1b0f2ea>\u001b[0m in \u001b[0;36mconvert_image_to_array\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Convert to Numpy Array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimages_as_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimages_as_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    102\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    103\u001b[0m                           'The use of `array_to_img` requires PIL.')\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2704\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2705\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file '../input/Training/Apple Red 1/.DS_Store'"
     ]
    }
   ],
   "source": [
    "# We just have the file names in the x set. Let's load the images and convert them into array.\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "def convert_image_to_array(files):\n",
    "    images_as_array=[]\n",
    "    for file in files:\n",
    "        # Convert to Numpy Array\n",
    "        images_as_array.append(img_to_array(load_img(file)))\n",
    "    return images_as_array\n",
    "\n",
    "x_train = np.array(convert_image_to_array(x_train))\n",
    "print('Training set shape : ',x_train.shape)\n",
    "\n",
    "x_valid = np.array(convert_image_to_array(x_valid))\n",
    "print('Validation set shape : ',x_valid.shape)\n",
    "\n",
    "x_test = np.array(convert_image_to_array(x_test))\n",
    "print('Test set shape : ',x_test.shape)\n",
    "\n",
    "print('1st training image shape ',x_train[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb44a8c41693a8e14332cc734dd2ced9d5582986"
   },
   "outputs": [],
   "source": [
    "print('1st training image as array',x_train[0]) # don't worry if you see only 255s..\n",
    "# there are elements will other values too :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9bbd173bdc8646ebafeeb31e492c80199683c72"
   },
   "outputs": [],
   "source": [
    "# time to re-scale so that all the pixel values lie within 0 to 1\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_valid = x_valid.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cb2bff712654024215ef79585dba06dd0114396",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's visualize the first 10 training images!\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize =(30,5))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2,5,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(np.squeeze(x_train[i]))\n",
    "# Yummy fruits ;) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d14849fa59a55c57dfdd9622a4d9bcc90de8971b"
   },
   "outputs": [],
   "source": [
    "#Simple CNN from scratch - we are using 3 Conv layers followed by maxpooling layers.\n",
    "# At the end we add dropout, flatten and some fully connected layers(Dense).\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(150))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(95,activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dff4d3931ad4ff2748d7681a9767007877694b12"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "print('Compiled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ac38a4408414793435002ff4af1ab25bbf082a8"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = 'cnn_from_scratch_fruits.hdf5', verbose = 1, save_best_only = True)\n",
    "\n",
    "history = model.fit(x_train,y_train,\n",
    "        batch_size = 32,\n",
    "        epochs=30,\n",
    "        validation_data=(x_valid, y_vaild),\n",
    "        callbacks = [checkpointer],\n",
    "        verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03edb7196563f35ee053d3306f594ece4f50139b"
   },
   "outputs": [],
   "source": [
    "# load the weights that yielded the best validation accuracy\n",
    "model.load_weights('cnn_from_scratch_fruits.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b9df1b9ce5cf750cff33b8ab975acee72c6aa4d"
   },
   "outputs": [],
   "source": [
    "# evaluate and print test accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])\n",
    "#98% accuracy !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d45b1a4b675f0c1189e8cbdd0876badac6fa1d6e"
   },
   "outputs": [],
   "source": [
    "# Let's visualize test prediction.\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# plot a random sample of test images, their predicted labels, and ground truth\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "for i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    pred_idx = np.argmax(y_pred[idx])\n",
    "    true_idx = np.argmax(y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n",
    "                 color=(\"green\" if pred_idx == true_idx else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f4754c40e12c2070c3721e46fba5465df9719151"
   },
   "outputs": [],
   "source": [
    "#Finally lets visualize the loss and accuracy wrt epochs\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(1)  \n",
    "   \n",
    " # summarize history for accuracy  \n",
    "   \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['acc'])  \n",
    "plt.plot(history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "   \n",
    " # summarize history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
